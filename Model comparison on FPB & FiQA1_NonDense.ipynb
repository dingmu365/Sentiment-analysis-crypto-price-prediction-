{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f328111",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import BERTFamily as fn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "from transformers import  BertTokenizer,DistilBertTokenizer, RobertaModel, RobertaTokenizer\n",
    "from transformers import  AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from dataclasses import make_dataclass\n",
    "from sklearn.metrics import f1_score,recall_score,precision_score,accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f149ae",
   "metadata": {},
   "source": [
    "# Comparison on Financial PhrraseBank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9fd5cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 177\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "MAX_LENGTH = 64\n",
    "BATCH_SIZE = 16\n",
    "NUM_CLASSES = 3 # neutral, positive, negative\n",
    "EPOCHS = 5\n",
    "DROPOUT_PROB = 0.1\n",
    "WEIGHT_DECAY = 0.01\n",
    "NFOLDS = 10\n",
    "LEARNING_RATE = 2e-5\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "loss_function = nn.CrossEntropyLoss().to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b130ec1a",
   "metadata": {},
   "source": [
    "## data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21367cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "statement_df = pd.read_csv('./data/all-data.csv', encoding='latin-1',\n",
    "                           header=None)\n",
    "statement_df.columns = ['sentiment', 'statement']\n",
    "statement_df = statement_df.drop_duplicates()\n",
    "statement_df['statement'] = statement_df['statement'].apply(fn.clean_statements)\n",
    "le = LabelEncoder()\n",
    "statement_df['sentiment'] = le.fit_transform(statement_df['sentiment'])\n",
    "#positive-2, neutral-1,negative-0\n",
    "df_train, df_test = train_test_split(statement_df,\n",
    "                                     test_size=0.2,\n",
    "                                     random_state=RANDOM_SEED,\n",
    "                                     stratify=statement_df['sentiment'].values)\n",
    "\n",
    "df_val, df_test = train_test_split(df_test,\n",
    "                                   test_size=0.5,\n",
    "                                   random_state=RANDOM_SEED,\n",
    "                                   stratify=df_test['sentiment'].values)\n",
    "\n",
    "df_train_full = pd.concat([df_train, df_val])\n",
    "keys=[\"sentiment\",\"statement\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0087e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   sentiment                                          statement\n0          1  According to Gran, the company has no plans to...\n1          1  Technopolis plans to develop in stages an area...\n2          0  The international electronic industry company ...\n3          2  With the new production plant the company woul...\n4          2  According to the company's updated strategy fo...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>statement</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>According to Gran, the company has no plans to...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Technopolis plans to develop in stages an area...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>The international electronic industry company ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>With the new production plant the company woul...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>According to the company's updated strategy fo...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "741d2f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def model_name(string):\n",
    "    string=string.replace(\"_fold_\",\"\")\n",
    "    string=string.replace(\"_\",\"\")\n",
    "    string=re.sub(r'\\d+', \"\",string, count=0, flags=0)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89358f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prediction(path,model_path,file,statement,device):\n",
    "        \n",
    "    if \"roberta\" in path:\n",
    "        model_type = \"roberta\"\n",
    "    elif \"distilbert\" in path:\n",
    "        model_type = \"distilbert\"\n",
    "    elif \"bert-base-cased\" in path:\n",
    "        model_type = \"bert-base-cased\"\n",
    "    elif \"bert-base-uncased\" in path:\n",
    "        model_type = \"bert-base-uncased\"\n",
    "    elif \"bert-large-cased\" in path:\n",
    "        model_type = \"bert-large-cased\"\n",
    "    elif \"bert-large-uncased\" in path:\n",
    "        model_type = \"bert-large-uncased\"\n",
    "    else:\n",
    "        print(\"wrong model type\")\n",
    "        return None\n",
    "   \n",
    "    model, tokenizer = fn.load_model(model_type, model_path)\n",
    "    model=model.to(device)\n",
    "    model = model.eval()\n",
    "    \n",
    "    predictions,preds = fn.pred_model(input_data=file[statement],\n",
    "                             model=model,\n",
    "                             tokenizer=tokenizer)\n",
    "    return predictions,preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af47f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = f\"./model/model_2021_08_03/best\"\n",
    "paths = os.listdir(dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7959dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#micro-F1 = micro-precision = micro-recall = accuracy\n",
    "# cm = confusion_matrix(labels, preds)\n",
    "# recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
    "# precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
    "# print(cm)\n",
    "# print(recall,precision)\n",
    "# print(classification_report(labels,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38fc55d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(preds,predictions,lables,name):\n",
    "    labels=df_test[\"sentiment\"]\n",
    "    record=pd.DataFrame(columns=[\"model\",\"accuracy\",\"MSE\"])\n",
    "    \n",
    "    accuracy=accuracy_score(predictions,labels)\n",
    "    loss=loss_function(preds,\n",
    "               torch.from_numpy(labels.values).type(torch.LongTensor))\n",
    "    record=record.append({\"model\":name,\"accuracy\":accuracy,\"MSE\":loss.item()},ignore_index=True)\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1e50280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['_roberta_fold_9.bin',\n '_bert-base-cased_fold_2.bin',\n '_distilbert_fold_2.bin',\n '_bert-base-uncased_fold_1.bin']"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da48fe37",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 148.00 MiB (GPU 0; 14.76 GiB total capacity; 13.51 GiB already allocated; 41.75 MiB free; 13.67 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-35-291be2ef018c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mpath\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpaths\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0mmodel_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdir\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"/\"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mpath\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m     \u001B[0mprediction\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mpreds\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mload_prediction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mmodel_path\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mfile\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mstatement\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m     \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreplace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\".bin\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m     \u001B[0mprediction\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"model\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-28-ff1ad83dcdd4>\u001B[0m in \u001B[0;36mload_prediction\u001B[0;34m(path, model_path, file, statement, device)\u001B[0m\n\u001B[1;32m     17\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m     \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtokenizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meval\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Thesis/vol/fob-vol7/nebenf19/dingneng/Thesis/BERTFamily.py\u001B[0m in \u001B[0;36mload_model\u001B[0;34m(model_type, PATH)\u001B[0m\n\u001B[1;32m    408\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"given wrong model type\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    409\u001B[0m         \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 410\u001B[0;31m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mPATH\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    411\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    412\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/ding_env/lib/python3.6/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[1;32m    605\u001B[0m                     \u001B[0mopened_file\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mseek\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0morig_position\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    606\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjit\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 607\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0m_load\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_zipfile\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpickle_module\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mpickle_load_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    608\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0m_legacy_load\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpickle_module\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mpickle_load_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    609\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/ding_env/lib/python3.6/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m_load\u001B[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001B[0m\n\u001B[1;32m    880\u001B[0m     \u001B[0munpickler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mUnpicklerWrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_file\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mpickle_load_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    881\u001B[0m     \u001B[0munpickler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpersistent_load\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpersistent_load\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 882\u001B[0;31m     \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0munpickler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    883\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    884\u001B[0m     \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_validate_loaded_sparse_tensors\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/ding_env/lib/python3.6/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mpersistent_load\u001B[0;34m(saved_id)\u001B[0m\n\u001B[1;32m    855\u001B[0m         \u001B[0mdata_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlocation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    856\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mloaded_storages\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 857\u001B[0;31m             \u001B[0mload_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_maybe_decode_ascii\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlocation\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    858\u001B[0m         \u001B[0mstorage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloaded_storages\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    859\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mstorage\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/ding_env/lib/python3.6/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mload_tensor\u001B[0;34m(data_type, size, key, location)\u001B[0m\n\u001B[1;32m    844\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    845\u001B[0m         \u001B[0mstorage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mzip_file\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_storage_from_record\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstorage\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 846\u001B[0;31m         \u001B[0mloaded_storages\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrestore_location\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstorage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlocation\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    847\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    848\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mpersistent_load\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msaved_id\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/ding_env/lib/python3.6/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mrestore_location\u001B[0;34m(storage, location)\u001B[0m\n\u001B[1;32m    825\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmap_location\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    826\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mrestore_location\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstorage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlocation\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 827\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mdefault_restore_location\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstorage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmap_location\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    828\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    829\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mrestore_location\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstorage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlocation\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/ding_env/lib/python3.6/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mdefault_restore_location\u001B[0;34m(storage, location)\u001B[0m\n\u001B[1;32m    173\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mdefault_restore_location\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstorage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlocation\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    174\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m \u001B[0;32min\u001B[0m \u001B[0m_package_registry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 175\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstorage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlocation\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    176\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mresult\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    177\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/ding_env/lib/python3.6/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m_cuda_deserialize\u001B[0;34m(obj, location)\u001B[0m\n\u001B[1;32m    155\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mstorage_type\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 157\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    158\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    159\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/ding_env/lib/python3.6/site-packages/torch/_utils.py\u001B[0m in \u001B[0;36m_cuda\u001B[0;34m(self, device, non_blocking, **kwargs)\u001B[0m\n\u001B[1;32m     77\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     78\u001B[0m             \u001B[0mnew_type\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 79\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mnew_type\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcopy_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_blocking\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     80\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     81\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/ding_env/lib/python3.6/site-packages/torch/cuda/__init__.py\u001B[0m in \u001B[0;36m_lazy_new\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m    526\u001B[0m     \u001B[0;31m# We may need to call lazy init again if we are a forked child\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    527\u001B[0m     \u001B[0;31m# del _CudaBase.__new__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 528\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_CudaBase\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__new__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcls\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    529\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    530\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 148.00 MiB (GPU 0; 14.76 GiB total capacity; 13.51 GiB already allocated; 41.75 MiB free; 13.67 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport BERTFamily\n",
    "import BERTFamily as fn\n",
    "\n",
    "model_preds=pd.DataFrame()\n",
    "total_model_record=pd.DataFrame(columns=[\"model\",\"MSE\",\"accuracy\"])\n",
    "labels=df_test[\"sentiment\"]\n",
    "file=df_test\n",
    "statement=\"statement\"\n",
    "for path in paths:\n",
    "    model_path = dir + \"/\" + path\n",
    "    prediction,preds=load_prediction(path,model_path,file,statement,device)\n",
    "    name=model_name(path.replace(\".bin\",\"\"))\n",
    "    prediction[\"model\"]=name\n",
    "    record=scores(preds,prediction[0],labels,name)\n",
    "\n",
    "    total_model_record=total_model_record.append(record,ignore_index=True)\n",
    "\n",
    "    model_preds=model_preds.append(prediction,ignore_index=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceba2620",
   "metadata": {},
   "source": [
    "## Baseline: LM_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6db7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LM_dictionary import LM_prediction\n",
    "\n",
    "LM_preds = LM_prediction(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a3691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(LM_preds.values.astype('float') ,labels)\n",
    "\n",
    "total_model_record=total_model_record.append({\"model\":\"LM\",\"MSE\":None,\"accuracy\":accuracy},ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7833fa96",
   "metadata": {},
   "source": [
    "## case-base-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d2eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104159c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=df_test[\"sentiment\"]\n",
    "record=pd.DataFrame()\n",
    "Point = make_dataclass(\"Point\", [(\"model\", str), (\"accuracy\")])\n",
    "model=model_name(\"_bert-base-cased_fold_0\")\n",
    "print(model)\n",
    "preds=model_preds[model_preds[\"model\"]==model][0]\n",
    "print(accuracy_score(preds,labels))\n",
    "print(classification_report(preds,labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4681c72",
   "metadata": {},
   "source": [
    "## uncase-base-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45cd1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"_bert-base-uncased_fold_3\"\n",
    "model=model_name(model)\n",
    "preds=model_preds[model_preds[\"model\"]==model][0]\n",
    "print(accuracy_score(preds,labels))\n",
    "print(classification_report(preds,labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85183da",
   "metadata": {},
   "source": [
    "## case-large-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f5a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"_bert-large-cased_fold_0\"\n",
    "model=model_name(model)\n",
    "print(model)\n",
    "preds=model_preds[model_preds[\"model\"]==model][0]\n",
    "print(accuracy_score(preds,labels))\n",
    "print(classification_report(preds,labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d5259e",
   "metadata": {},
   "source": [
    "## uncase-large-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cdea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"_bert-large-uncased_fold_2\"\n",
    "model=model_name(model)\n",
    "print(model)\n",
    "preds=model_preds[model_preds[\"model\"]==model][0]\n",
    "print(accuracy_score(preds,labels))\n",
    "print(classification_report(preds,labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc62b48",
   "metadata": {},
   "source": [
    "## RoBERTa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ed17b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"_roberta_fold_4\"\n",
    "model=model_name(model)\n",
    "print(model)\n",
    "preds=model_preds[model_preds[\"model\"]==model][0]\n",
    "print(accuracy_score(preds,labels))\n",
    "print(classification_report(preds,labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9651713",
   "metadata": {},
   "source": [
    "## DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a34846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"_distilbert_fold_2\"\n",
    "model=model_name(model)\n",
    "print(model)\n",
    "preds=model_preds[model_preds[\"model\"]==model][0]\n",
    "print(accuracy_score(preds,labels))\n",
    "print(classification_report(preds,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec2e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport FinBERT\n",
    "\n",
    "from FinBERT import *\n",
    "result=FinBERT_prediction(data=df_test,statement=\"statement\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7bd10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = [x for y in [df_test[\"sentiment\"]] for x in y]\n",
    "pres = [x for y in [result[\"prediction\"]] for x in y]\n",
    "preds=[x for y in [result[\"preds\"]] for x in y]\n",
    "accuracy_score(y_true=actual, y_pred=pres)\n",
    "record=scores(torch.as_tensor(np.array(preds).astype('float')),pres,labels,name=\"finbert\")\n",
    "total_model_record=total_model_record.append(record,ignore_index=True)\n",
    "print(classification_report(pres,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5ac02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_model_record.sort_values(\"MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c198b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_model_record.sort_values(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a359503",
   "metadata": {},
   "source": [
    "# Comparison on FiQA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37618673",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "\n",
    "path_read=f\"./data/task1_headline_ABSA_train.json\"\n",
    "QA_data=pd.DataFrame(columns=[\"statement\",\"sentiment\"])\n",
    "with open(path_read) as f:\n",
    "    data = json.load(f)\n",
    "    data_items = data.items()\n",
    "    data_list = list(data_items)\n",
    "    for i,content in data_items:\n",
    "        data_items = data.items()\n",
    "        data_list = list(data_items)\n",
    "        QA_data=QA_data.append({\"statement\":content[\"sentence\"],\"sentiment\":content[\"info\"][0]['sentiment_score']},ignore_index=True)\n",
    "\n",
    "f.close()\n",
    "QA_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c875b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3122f2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}